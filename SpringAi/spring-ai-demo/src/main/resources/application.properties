spring.application.name=spring-ai-demo
server.port=8000
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=llama3.2:latest
spring.ai.ollama.chat.options.temperature=0.7
spring.ai.ollama.chat.options.max-tokens=150
spring.ai.ollama.chat.options.format=json

spring.main.web-application-type=NONE

# Ollama embedding model
#spring.ai.ollama.embedding.options.model=llama3.2:embedding

# Ollama auto-pull model configuration
spring.ai.ollama.init.pull-model-strategy=always
spring.ai.ollama.init.timeout=15m
spring.ai.ollama.init.max-retries=2
